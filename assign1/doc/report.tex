\documentclass[11pt,a4paper]{article}

\usepackage[margin=.75in]{geometry}
\usepackage{indentfirst}
\usepackage{listings}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{color}
\usepackage{hyperref}
\usepackage[super]{nth}
\usepackage{siunitx}
\usepackage{graphicx}
\graphicspath{ {./resources/} }
\usepackage{float}
\usepackage{pgfplots}
\usepackage{subcaption}
\pgfplotsset{compat=1.18,table/search path={resources}}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\definecolor{orange}{rgb}{.7,.3,0}

\makeatletter
\lst@InstallKeywords k{types}{typestyle}\slshape{typestyle}{}ld
\makeatother

\lstset{
    language=c,
    aboveskip=3mm,
    belowskip=3mm,
    showstringspaces=false,
    basicstyle={\small\ttfamily},
    keywordstyle=\color{blue},
    commentstyle=\color{dkgreen},
    stringstyle=\color{mauve},
    typestyle=\color{orange},
    breaklines=true,
    breakatwhitespace=true
}

\lstset{
    language=java,
    aboveskip=3mm,
    belowskip=3mm,
    showstringspaces=false,
    basicstyle={\small\ttfamily},
    keywordstyle=\color{blue},
    commentstyle=\color{dkgreen},
    stringstyle=\color{mauve},
    typestyle=\color{orange},
    breaklines=true,
    breakatwhitespace=true
}

\title{Parallel and Distributed Computing -- \nth{1} Project Report}
\author{Guilherme Almeida, João Malva, Nuno Pereira}

\begin{document}

\maketitle

\section{Introduction}

The goal of this project was to develop a series of algorithms that perform matrix multiplication and analyze their performance using various techniques, namely:

\begin{itemize}
    \item Normal Matrix Multiplication;
    \item "Line by Line" Matrix Multiplication;
    \item Block Matrix Multiplication;
\end{itemize}

\section{Algorithm Analysis}

The algorithms described were implemented using the C programming language, the Java programming language and the Performance API, PAPI for short.

PAPI is used in conjunction with the C code because it allows us to directly collect several metrics related to the performance of the algorithms developed.
It is not used with the Java code since it runs on the Java Virtual Machine, and therefore the performance registers are virtualized, which inhibits us from 

\subsection{Normal Matrix Multiplication}

This algorithm is the \begin{em}naïve\end{em} implementation of the normal matrix multiplication procedure.

It iterates through each line of the first matrix and each column of the second matrix to perform the dot product between each vector, accumulating the results in the destination matrix.

The algorithm can be (grossly) coded as the following:

\begin{algorithm}
    \caption{Naïve Matrix Multiplication Algorithm}
    \begin{algorithmic}[1]
        \Function{OnMult}{$a, b$}
            \State {$mx\_size \gets Lenght(a)$}\Comment{$a$ should have the same side length as $b$}
            \State {$c \gets matrix[mx\_size][mx\_size]$}\Comment{$c$ is initialized with $0$s}
            \For{$i \gets 0$ to $mx\_size$}
                \For{$j \gets 0$ to $mx\_size$}
                    \For{$k \gets 0$ to $mx\_size$}
                    \State {$c_{i,j} \gets c_{i,j} + a_{i,k} * b_{k,j}$}
                    \EndFor
                \EndFor
            \EndFor
            \State \Return $c$
        \EndFunction
    \end{algorithmic}
\end{algorithm}

\subsection{"Line by Line" Matrix Multiplication}

This algorithm is an improvement over the normal matrix multiplication algorithm.

It exploits the properties of cache locality to speed up the matrix product computations.

The algorithm can be (grossly) coded as the following:
\begin{algorithm}
    \caption{Line Matrix Multiplication Algorithm}
    \begin{algorithmic}[1]
        \Function{OnMultLine}{$a, b$}
            \State {$mx\_size \gets Lenght(a)$}\Comment{$a$ should have the same side length as $b$}
            \State {$c \gets matrix[mx\_size][mx\_size]$}\Comment{$c$ is initialized with $0$s}
            \For{$i \gets 0$ to $mx\_size$}
                \For{$k \gets 0$ to $mx\_size$}
                    \For{$j \gets 0$ to $mx\_size$}
                        \State {$c_{i,j} \gets c_{i,j} + a_{i,k} * b_{k,j}$}
                    \EndFor
                \EndFor
            \EndFor
            \State \Return $c$
        \EndFunction
    \end{algorithmic}
\end{algorithm}

The main difference between this algorithm and the previous one is that, by changing the order of iteration of \lstinline{j} and \lstinline{k}, the processor does not need to load a new set of data into cache due to the multiplication order following the second matrix's lines, thus reducing drastically the number of cache misses resulting from the \begin{em}naïve\end{em} implementation.

\subsection{Block Matrix Multiplication}

This reasoning behind this algorithm is to "divide and conquer": by dividing the original matrix into many sub-matrices and performing the multiplication on these, the process is sped up.

The algorithm used with each sub-matrix is the "Line by Line" one since it offers better performance over the \begin{em}naïve\end{em} implementation.

Since the code for this algorithm is pretty big, it is not included in the report.

This algorithm also has another input parameter: the block size. This value controls the size of the resulting sub-matrices, which affects the performance of the algorithm, as can be seen in the following section.

\pagebreak

\section{Performance Analysis}

The performance metrics collected to analyze the developed algorithms were:

\begin{itemize}
    \item The execution time;
    \item The Level 1 Data Cache misses;
    \item The Level 2 Data Cache misses;
\end{itemize}

These metrics give us an overview of the behavior of the algorithms and allow us to derive another important metric: Gflops/s. This value indicates how many floating point operations were performed per second: (typically) the higher the value the more operations were performed and the faster the algorithm was.

\subsection{Data graphics}

The following graphics depict the differences between the two languages used across the various metrics measured:

\subsubsection{GFlop/\unit{\second}}

\begin{figure}
    \centering
    \begin{tikzpicture}
        \begin{axis}[
                title={Naïve Implementation},
                xlabel={Size},
                ylabel={GFlop/\unit{\second}},
                legend pos=north east,
                xtick=data,
                width=16cm,
                height=10cm,
            ]
            \addplot[
                smooth,
                mark=o,
                red
            ] table [x=Matrix Size, y=C_N, col sep=comma]{CPD-CSV-GFlops.csv};
            \addlegendentry{C}
            \addplot[
                smooth,
                mark=x,
                blue
            ] table [x=Matrix Size, y=Java_N, col sep=comma]{CPD-CSV-GFlops.csv};
            \addlegendentry{Java}
        \end{axis}
    \end{tikzpicture}
    \caption{GFlop/\unit{\second} for both implementations of the naïve algorithm}
    \label{fig:ngf}
\end{figure}

\begin{figure}
    \centering
    \begin{tikzpicture}
        \begin{axis}[
                title={"Line by Line" Implementation},
                xlabel={Size},
                ylabel={GFlop/\unit{\second}},
                legend pos=north east,
                xtick=data,
                width=16cm,
                height=10cm,
            ]
            \addplot[
                smooth,
                mark=o,
                red
            ] table [x=Matrix Size, y=C_L, col sep=comma]{CPD-CSV-GFlops.csv};
            \addlegendentry{C}
            \addplot[
                smooth,
                mark=x,
                blue
            ] table [x=Matrix Size, y=Java_L, col sep=comma]{CPD-CSV-GFlops.csv};
            \addlegendentry{Java}
        \end{axis}
    \end{tikzpicture}
    \caption{GFlop/\unit{\second} for both implementations of the "line by line" algorithm}    
    \label{fig:lblgf}
\end{figure}

\section{Conclusions}

All of the project's goals were achieved -

\appendix
\section{Appendix}

\subsection{Code}

\noindent Versions of the algorithms in C and Java are available in folder \lstinline{src/}.

\end{document}
